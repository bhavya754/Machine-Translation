{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bs3118_hw5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "552QcaE33U1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5qXyJxYD593j",
        "colab_type": "code",
        "outputId": "471616eb-c245-4d2c-f5f2-3debfc03e186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VtYXP-576PSA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import sacrebleu\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4kIwwJyerZu9",
        "colab_type": "code",
        "outputId": "f916d5a4-8d8c-4ab4-b976-27afee74e527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "lines = [line.rstrip('\\n') for line in open('spa.txt')]\n",
        "\n",
        "my_data = []\n",
        "for line in lines:\n",
        "  cols = line.split('\\t')\n",
        "  my_data.append(tuple(cols))\n",
        "        \n",
        "print(my_data[1:10])\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(my_data)\n",
        "print(my_data[1:10])\n",
        "\n",
        "en_es_sentences = my_data[10:2010]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Go.', 'Vete.'), ('Go.', 'Vaya.'), ('Go.', 'Váyase.'), ('Hi.', 'Hola.'), ('Run!', '¡Corre!'), ('Run.', 'Corred.'), ('Who?', '¿Quién?'), ('Fire!', '¡Fuego!'), ('Fire!', '¡Incendio!')]\n",
            "[('Do you really want to be here?', '¿Realmente querés estar acá?'), ('She is as beautiful as Snow White.', 'Ella es bella como Blancanieves.'), (\"There are few men who don't know that.\", 'Hay pocos hombres que no lo saben.'), ('Tom changes channels during commercials.', 'Tom cambia de canal durante los comerciales.'), (\"It's a wonder they're still awake.\", 'Es un milagro que sigan despiertas.'), ('I will clean this up later.', 'Lo limpiaré más tarde.'), ('Let him go!', '¡Déjale irse!'), ('I study math harder than you do.', 'Yo estudio mates mucho más que tú.'), ('We need to clean the car.', 'Necesitamos lavar el auto.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oC4k6fgl6gEq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LCC2LG2UunC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1: Converting English to Spanish\n",
        "\n",
        "To convert English to Spanish, we simply follow the method given in the sample tutorial. We train the model on 2000 rows of randomly selected data. The tuples containing the English and Spanish translations is stored in variable *sentences*.\n",
        "\n",
        "The BLEU score achieved is 67.4\n",
        "\n",
        "We also store the hypotheses and the corresponding inputs given tot the model as this will later be used for back translation. \n",
        "\n",
        "\n",
        "Note: As discussed in the OH, I have not used a train and test split. Instead it is tested on the entire dataset. \n"
      ]
    },
    {
      "metadata": {
        "id": "DFLe3U-Uxy_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = en_es_sentences\n",
        "sentences = [(preprocess(source), preprocess(target)) for (source, target) in sentences]\n",
        "source_sentences, target_sentences = list(zip(*sentences))\n",
        "\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer.fit_on_texts(source_sentences)\n",
        "source_data = source_tokenizer.texts_to_sequences(source_sentences)\n",
        "source_data = tf.keras.preprocessing.sequence.pad_sequences(source_data, padding='post')\n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(target_sentences)\n",
        "target_data = target_tokenizer.texts_to_sequences(target_sentences)\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, padding='post')\n",
        "target_labels = np.zeros(target_data.shape)\n",
        "target_labels[:,0:target_data.shape[1] -1] = target_data[:,1:]\n",
        "\n",
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rKH4G_1HBWo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))\n",
        "  \n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state\n",
        "  \n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "def translate(idx=None):\n",
        "\n",
        "  if idx == None: \n",
        "    idx = np.random.choice(len(sentences))\n",
        "\n",
        "  input_sent = source_data[idx]\n",
        "  input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "\n",
        "  hidden_state = encoder.init_state(batch_size=1)\n",
        "  output, hidden_state = encoder(input_sent, hidden_state)\n",
        "\n",
        "  decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "  out_words = []\n",
        "\n",
        "  decoder_state = hidden_state\n",
        "\n",
        "  while True:\n",
        "\n",
        "      decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "      decoder_input = tf.argmax(decoder_output, -1)\n",
        "      word_idx = decoder_input.numpy()[0][0]\n",
        "      # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "      # before the decoder is trained, just stop translating and return\n",
        "      # what we have)\n",
        "      if word_idx == 0: \n",
        "        out_words.append('<end>')\n",
        "      else:\n",
        "        out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "      if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "        break\n",
        "\n",
        "  translation = ' '.join(out_words)    \n",
        "  return sentences[idx][0], sentences[idx][1], translation\n",
        "@tf.function\n",
        "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N6BD2AWIvfsx",
        "colab_type": "code",
        "outputId": "47dec022-00ab-4c48-96ac-af5022042185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2604
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_data, target_data, target_labels)).batch(batch_size)\n",
        "embedding_size = 32\n",
        "rnn_size = 64\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "EPOCHS = 300\n",
        "encoder = Encoder()\n",
        "decoder = Decoder()\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  en_initial_states = encoder.init_state(batch_size)\n",
        "\n",
        "  for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "    loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "    input_sent, target_sent, translation = translate(idx=None)\n",
        "    print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))\n",
        "\n",
        "references_eng, hypotheses_eng, input_eng = [], [], []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references_eng.append(target_sent)\n",
        "  hypotheses_eng.append(\"<start> \" + translation)\n",
        "  input_eng.append(input_sent)\n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses_eng, [references_eng])\n",
        "print(results)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.4114, Time 6.57 sec\n",
            "Input: <start> It s getting harder for me to concentrate . <end>\n",
            "Target: <start> Cada vez me cuesta mas concentrarme . <end>\n",
            "Translation: tom no que . <end>\n",
            "\n",
            "Epoch #10, Loss 0.9640, Time 2.20 sec\n",
            "Input: <start> Tom cut his finger on a piece of glass . <end>\n",
            "Target: <start> Tom se corto el dedo con un pedazo de vidrio . <end>\n",
            "Translation: tom no es un poco . <end>\n",
            "\n",
            "Epoch #20, Loss 0.7012, Time 2.06 sec\n",
            "Input: <start> I know who you want to talk to . <end>\n",
            "Target: <start> Se con quien quieres hablar . <end>\n",
            "Translation: no me gusta el vacuno . <end>\n",
            "\n",
            "Epoch #30, Loss 0.5251, Time 2.05 sec\n",
            "Input: <start> No one knows the answer . <end>\n",
            "Target: <start> Nadie sabe la respuesta . <end>\n",
            "Translation: la noticia la entristecio . <end>\n",
            "\n",
            "Epoch #40, Loss 0.3845, Time 2.08 sec\n",
            "Input: <start> Maybe they will come and maybe they won t . <end>\n",
            "Target: <start> Puede que vengan y puede que no . <end>\n",
            "Translation: a mi tambien es una persona nueva . <end>\n",
            "\n",
            "Epoch #50, Loss 0.3273, Time 2.35 sec\n",
            "Input: <start> We re very proud of Tom . <end>\n",
            "Target: <start> Estamos muy orgullosos de Tomas . <end>\n",
            "Translation: a ver el cafe . <end>\n",
            "\n",
            "Epoch #60, Loss 0.2660, Time 2.06 sec\n",
            "Input: <start> I want my family back . <end>\n",
            "Target: <start> Quiero a mi familia de vuelta . <end>\n",
            "Translation: quiero que estes segura . <end>\n",
            "\n",
            "Epoch #70, Loss 0.2180, Time 2.09 sec\n",
            "Input: <start> Unemployment is high . <end>\n",
            "Target: <start> El desempleo esta alto . <end>\n",
            "Translation: el vendra a la puerta eran las chica . <end>\n",
            "\n",
            "Epoch #80, Loss 0.1648, Time 2.10 sec\n",
            "Input: <start> Tom s starting to go bald . <end>\n",
            "Target: <start> Tomas esta empezando a quedarse pelado . <end>\n",
            "Translation: tomas esta empezando a quedarse pelado . <end>\n",
            "\n",
            "Epoch #90, Loss 0.1313, Time 2.38 sec\n",
            "Input: <start> You were alone at that time , weren t you ? <end>\n",
            "Target: <start> Entonces estabas solo , ¿ verdad ? <end>\n",
            "Translation: llegaste tarde , ¿ verdad ? <end>\n",
            "\n",
            "Epoch #100, Loss 0.1002, Time 2.11 sec\n",
            "Input: <start> She wore a beautiful dress . <end>\n",
            "Target: <start> Ella llevaba un hermoso vestido . <end>\n",
            "Translation: ella dijo que podria ser verdad . <end>\n",
            "\n",
            "Epoch #110, Loss 0.0859, Time 2.12 sec\n",
            "Input: <start> Don t feed the animals . <end>\n",
            "Target: <start> No de de comer a los animales . <end>\n",
            "Translation: no me gusta ninguno . <end>\n",
            "\n",
            "Epoch #120, Loss 0.0727, Time 2.12 sec\n",
            "Input: <start> He was charged with conspiracy . <end>\n",
            "Target: <start> Fue denunciado por asociacion ilicita . <end>\n",
            "Translation: fue denunciado por asociacion ilicita . <end>\n",
            "\n",
            "Epoch #130, Loss 0.0634, Time 2.09 sec\n",
            "Input: <start> Tom asked Mary to keep an eye on John . <end>\n",
            "Target: <start> Tom le pidio a Mary que no perdiera de vista a John . <end>\n",
            "Translation: tom iba al cine cada semana . <end>\n",
            "\n",
            "Epoch #140, Loss 0.0550, Time 2.10 sec\n",
            "Input: <start> Tom is particular about what he wears . <end>\n",
            "Target: <start> Tom es muy particular con respecto a la ropa que lleva . <end>\n",
            "Translation: tom es muy particular con respecto a la ropa que lleva . <end>\n",
            "\n",
            "Epoch #150, Loss 0.0498, Time 2.11 sec\n",
            "Input: <start> Forget Tom . <end>\n",
            "Target: <start> Olvidate de Tomas . <end>\n",
            "Translation: olvidate de tomas . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0250, Time 2.12 sec\n",
            "Input: <start> A river divides the town . <end>\n",
            "Target: <start> Un rio divide la ciudad . <end>\n",
            "Translation: un rio divide la ciudad . <end>\n",
            "\n",
            "Epoch #170, Loss 0.0262, Time 2.11 sec\n",
            "Input: <start> He s going back to America . <end>\n",
            "Target: <start> El se va de regreso a America . <end>\n",
            "Translation: el se puso a su siempre y haya leido . <end>\n",
            "\n",
            "Epoch #180, Loss 0.0381, Time 2.12 sec\n",
            "Input: <start> We must consider all options . <end>\n",
            "Target: <start> Debemos considerar todas las opciones . <end>\n",
            "Translation: estamos en la ciudad es para ti . <end>\n",
            "\n",
            "Epoch #190, Loss 0.0261, Time 2.09 sec\n",
            "Input: <start> Tom shut the door quietly . <end>\n",
            "Target: <start> Tomas cerro la puerta despacio . <end>\n",
            "Translation: tomas cerro la puerta despacio . <end>\n",
            "\n",
            "Epoch #200, Loss 0.0296, Time 2.39 sec\n",
            "Input: <start> Tom lied to you . <end>\n",
            "Target: <start> Tom te ha mentido . <end>\n",
            "Translation: tom te ha mentido . <end>\n",
            "\n",
            "Epoch #210, Loss 0.0159, Time 2.10 sec\n",
            "Input: <start> I d love to dance with you . <end>\n",
            "Target: <start> Me encantaria bailar con vos . <end>\n",
            "Translation: me pondre en contacto contigo . <end>\n",
            "\n",
            "Epoch #220, Loss 0.0368, Time 2.09 sec\n",
            "Input: <start> Don t let the kids watch this film . <end>\n",
            "Target: <start> No dejes que los ninos vean esta pelicula . <end>\n",
            "Translation: no dejes que los ninos vean esta pelicula . <end>\n",
            "\n",
            "Epoch #230, Loss 0.0041, Time 2.08 sec\n",
            "Input: <start> How many cats are there in this house ? <end>\n",
            "Target: <start> ¿ Cuantos gatos hay en esta casa ? <end>\n",
            "Translation: ¿ cuantos gatos hay en esta casa ? <end>\n",
            "\n",
            "Epoch #240, Loss 0.0050, Time 2.12 sec\n",
            "Input: <start> Tom gave Mary a quick kiss . <end>\n",
            "Target: <start> Tom le dio un beso rapido a Mary . <end>\n",
            "Translation: tom le dio un beso rapido a mary . <end>\n",
            "\n",
            "Epoch #250, Loss 0.0067, Time 2.08 sec\n",
            "Input: <start> She heard him sing . <end>\n",
            "Target: <start> Ella le oyo cantar . <end>\n",
            "Translation: ella le dio el dinero . <end>\n",
            "\n",
            "Epoch #260, Loss 0.0028, Time 2.10 sec\n",
            "Input: <start> Our team won . <end>\n",
            "Target: <start> Nuestro equipo gano . <end>\n",
            "Translation: nuestro equipo gano . <end>\n",
            "\n",
            "Epoch #270, Loss 0.0031, Time 2.15 sec\n",
            "Input: <start> It will not be long before one out of five people owns a car . <end>\n",
            "Target: <start> No pasara mucho tiempo antes de que una de cada cinco personas posea un coche . <end>\n",
            "Translation: no pasara mucho tiempo antes de que una de cada cinco personas posea un coche . <end>\n",
            "\n",
            "Epoch #280, Loss 0.0029, Time 2.06 sec\n",
            "Input: <start> Let me introduce you to a good dentist . <end>\n",
            "Target: <start> Dejame presentarte a un buen dentista . <end>\n",
            "Translation: dejame presentarte a un buen dentista . <end>\n",
            "\n",
            "Epoch #290, Loss 0.0039, Time 2.08 sec\n",
            "Input: <start> Show me the money . <end>\n",
            "Target: <start> Muestreme el dinero . <end>\n",
            "Translation: muestreme el dinero . <end>\n",
            "\n",
            "BLEU(score=66.78051464567865, counts=[15652, 11336, 8823, 6888], totals=[18407, 16407, 14407, 12407], precisions=[85.03286793067855, 69.09246053513745, 61.24106337197196, 55.51704682840332], bp=0.9989140469113621, sys_len=18407, ref_len=18427)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSEd3Gik2Joe",
        "colab_type": "code",
        "outputId": "31c002a2-d62e-445e-f030-a7c48dae72d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "references_eng, hypotheses_eng, input_eng = [], [], []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references_eng.append(target_sent)\n",
        "  hypotheses_eng.append(\"<start> \" + translation)\n",
        "  input_eng.append(input_sent)\n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses_eng, [references_eng])\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=67.43784658833205, counts=[15983, 11649, 9150, 7220], totals=[18741, 16741, 14741, 12741], precisions=[85.28360279600875, 69.5836568902694, 62.07177260701445, 56.66745153441645], bp=0.9977081955412436, sys_len=18741, ref_len=18784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RGUq4I6TRXzT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2: Converting Spanish to English\n",
        "\n",
        "To convert Spanish to English, we first need to change the order of tuples in *sentences* . We then train a new model (overwriting the previous one ).\n",
        "\n",
        "The BLEU score achieved is 65.4"
      ]
    },
    {
      "metadata": {
        "id": "MQdkFJPYReuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "es_en_sentences = []\n",
        "\n",
        "for i in range(0,len(en_es_sentences)):\n",
        "  sentence = en_es_sentences[i]\n",
        "  data_point = []\n",
        "  data_point.append(sentence[1])\n",
        "  data_point.append(sentence[0])\n",
        "  es_en_sentences.append(tuple(data_point))\n",
        "\n",
        "sentences = es_en_sentences\n",
        "sentences = [(preprocess(source), preprocess(target)) for (source, target) in sentences]\n",
        "source_sentences, target_sentences = list(zip(*sentences))\n",
        "\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer.fit_on_texts(source_sentences)\n",
        "source_data = source_tokenizer.texts_to_sequences(source_sentences)\n",
        "source_data = tf.keras.preprocessing.sequence.pad_sequences(source_data, padding='post')\n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(target_sentences)\n",
        "target_data = target_tokenizer.texts_to_sequences(target_sentences)\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, padding='post')\n",
        "target_labels = np.zeros(target_data.shape)\n",
        "target_labels[:,0:target_data.shape[1] -1] = target_data[:,1:]\n",
        "\n",
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KjUhcHTUBRx1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))\n",
        "  \n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state\n",
        "  \n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "def translate(idx=None):\n",
        "\n",
        "  if idx == None: \n",
        "    idx = np.random.choice(len(sentences))\n",
        "\n",
        "  input_sent = source_data[idx]\n",
        "  input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "\n",
        "  hidden_state = encoder.init_state(batch_size=1)\n",
        "  output, hidden_state = encoder(input_sent, hidden_state)\n",
        "\n",
        "  decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "  out_words = []\n",
        "\n",
        "  decoder_state = hidden_state\n",
        "\n",
        "  while True:\n",
        "\n",
        "      decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "      decoder_input = tf.argmax(decoder_output, -1)\n",
        "      word_idx = decoder_input.numpy()[0][0]\n",
        "      # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "      # before the decoder is trained, just stop translating and return\n",
        "      # what we have)\n",
        "      if word_idx == 0: \n",
        "        out_words.append('<end>')\n",
        "      else:\n",
        "        out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "      if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "        break\n",
        "\n",
        "  translation = ' '.join(out_words)    \n",
        "  return sentences[idx][0], sentences[idx][1], translation\n",
        "@tf.function\n",
        "def train_step(source_seq, target_seq, target_labels, initial_state):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0dIUYWZy3ox",
        "colab_type": "code",
        "outputId": "7d42079d-c120-44c2-e969-7a72c47d4241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_data, target_data, target_labels)).batch(batch_size)\n",
        "embedding_size = 32\n",
        "rnn_size = 64\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "EPOCHS = 300\n",
        "encoder = Encoder()\n",
        "decoder = Decoder()\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  en_initial_states = encoder.init_state(batch_size)\n",
        "\n",
        "  for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "    loss = train_step(source_seq, target_seq, target_labels, en_initial_states)\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "    input_sent, target_sent, translation = translate(idx=None)\n",
        "    print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.5785, Time 4.39 sec\n",
            "Input: <start> ¿ Te sorprendiste ? <end>\n",
            "Target: <start> Were you surprised ? <end>\n",
            "Translation: i i the lot . <end>\n",
            "\n",
            "Epoch #10, Loss 1.0896, Time 2.10 sec\n",
            "Input: <start> Habia muchos ninos en la plaza . <end>\n",
            "Target: <start> There were many children in the square . <end>\n",
            "Translation: i m not a lot of the party is the same castle . <end>\n",
            "\n",
            "Epoch #20, Loss 0.8588, Time 2.38 sec\n",
            "Input: <start> Nadie quiere responder esa pregunta . <end>\n",
            "Target: <start> No one wants to answer that question . <end>\n",
            "Translation: i m not a little restless . <end>\n",
            "\n",
            "Epoch #30, Loss 0.6938, Time 2.10 sec\n",
            "Input: <start> Me das miedo . <end>\n",
            "Target: <start> You scare me . <end>\n",
            "Translation: i m not a bit tired . <end>\n",
            "\n",
            "Epoch #40, Loss 0.5445, Time 2.12 sec\n",
            "Input: <start> Tuve un mal sueno anoche . <end>\n",
            "Target: <start> I had a bad dream last night . <end>\n",
            "Translation: i m not a bit tired . <end>\n",
            "\n",
            "Epoch #50, Loss 0.4342, Time 2.12 sec\n",
            "Input: <start> ¿ Me vas a echar la culpa de esto tambien ? <end>\n",
            "Target: <start> Are you going to blame me for this , too ? <end>\n",
            "Translation: are you ready for halloween ? <end>\n",
            "\n",
            "Epoch #60, Loss 0.3439, Time 2.10 sec\n",
            "Input: <start> Parece que me agarre un resfriado . <end>\n",
            "Target: <start> I seem to have caught a cold . <end>\n",
            "Translation: i m not a bit tired . <end>\n",
            "\n",
            "Epoch #70, Loss 0.2843, Time 2.11 sec\n",
            "Input: <start> Hice humo mi plata en muy poco tiempo . <end>\n",
            "Target: <start> I went through my money in a very short time . <end>\n",
            "Translation: i ll be able to go on the river . <end>\n",
            "\n",
            "Epoch #80, Loss 0.2505, Time 2.10 sec\n",
            "Input: <start> Tomas se sento en el suelo . <end>\n",
            "Target: <start> Tom sat on the floor . <end>\n",
            "Translation: tom is my husband . <end>\n",
            "\n",
            "Epoch #90, Loss 0.2104, Time 2.11 sec\n",
            "Input: <start> Nadie me entiende como tu . <end>\n",
            "Target: <start> No one understands me like you do . <end>\n",
            "Translation: it s tom s pretty . <end>\n",
            "\n",
            "Epoch #100, Loss 0.1539, Time 2.09 sec\n",
            "Input: <start> El no puede ayudarte . <end>\n",
            "Target: <start> He can t help you . <end>\n",
            "Translation: he is a good guy . <end>\n",
            "\n",
            "Epoch #110, Loss 0.1376, Time 2.11 sec\n",
            "Input: <start> Las hojas empezaron a ponerse rojas y amarillas . <end>\n",
            "Target: <start> The leaves began to turn red and yellow . <end>\n",
            "Translation: the leaves began to turn red and yellow . <end>\n",
            "\n",
            "Epoch #120, Loss 0.1219, Time 2.10 sec\n",
            "Input: <start> El posiblemente este equivocado . <end>\n",
            "Target: <start> He s probably wrong . <end>\n",
            "Translation: he s a very one before . <end>\n",
            "\n",
            "Epoch #130, Loss 0.0782, Time 2.38 sec\n",
            "Input: <start> ¿ Cuanto cuesta este radio ? <end>\n",
            "Target: <start> How much is this radio ? <end>\n",
            "Translation: how much is going to you , will you to take care to you ? <end>\n",
            "\n",
            "Epoch #140, Loss 0.0706, Time 2.12 sec\n",
            "Input: <start> ¿ Has estado alguna vez en Australia ? <end>\n",
            "Target: <start> Have you ever been to Australia ? <end>\n",
            "Translation: have you ever played dominoes ? <end>\n",
            "\n",
            "Epoch #150, Loss 0.0646, Time 2.11 sec\n",
            "Input: <start> Mi escritorio es de madera . <end>\n",
            "Target: <start> My desk is made of wood . <end>\n",
            "Translation: my desk is made of wood . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0761, Time 2.11 sec\n",
            "Input: <start> Ella lo llamo por telefono . <end>\n",
            "Target: <start> She called him on the phone . <end>\n",
            "Translation: she called him . <end>\n",
            "\n",
            "Epoch #170, Loss 0.0497, Time 2.36 sec\n",
            "Input: <start> Si tuviera tiempo iria al cine . <end>\n",
            "Target: <start> If I had time , I would go to the movies . <end>\n",
            "Translation: if i had time , i would go to the movies . <end>\n",
            "\n",
            "Epoch #180, Loss 0.0425, Time 2.09 sec\n",
            "Input: <start> El parecia muy feliz . <end>\n",
            "Target: <start> He looked very happy . <end>\n",
            "Translation: he s collecting various data . <end>\n",
            "\n",
            "Epoch #190, Loss 0.0540, Time 2.39 sec\n",
            "Input: <start> Tom fue adoptado . <end>\n",
            "Target: <start> Tom was adopted . <end>\n",
            "Translation: tom was adopted . <end>\n",
            "\n",
            "Epoch #200, Loss 0.0460, Time 2.09 sec\n",
            "Input: <start> Debemos considerar todas las opciones . <end>\n",
            "Target: <start> We must consider all options . <end>\n",
            "Translation: we must consider all options . <end>\n",
            "\n",
            "Epoch #210, Loss 0.0378, Time 2.09 sec\n",
            "Input: <start> No se muy bien el frances . <end>\n",
            "Target: <start> I don t know French that well . <end>\n",
            "Translation: i don t know if i can t stand the heat . <end>\n",
            "\n",
            "Epoch #220, Loss 0.0199, Time 2.08 sec\n",
            "Input: <start> Es justo lo opuesto . <end>\n",
            "Target: <start> It s just the opposite . <end>\n",
            "Translation: it s just the opposite . <end>\n",
            "\n",
            "Epoch #230, Loss 0.0113, Time 2.08 sec\n",
            "Input: <start> Tom encontro a Mary . <end>\n",
            "Target: <start> Tom found Mary . <end>\n",
            "Translation: tom found mary . <end>\n",
            "\n",
            "Epoch #240, Loss 0.0153, Time 2.08 sec\n",
            "Input: <start> Me esfuerzo en ser atento . <end>\n",
            "Target: <start> I try my best to be considerate . <end>\n",
            "Translation: i try my best to be considerate . <end>\n",
            "\n",
            "Epoch #250, Loss 0.0077, Time 2.06 sec\n",
            "Input: <start> Lo espero con ganas . <end>\n",
            "Target: <start> I m looking forward to it . <end>\n",
            "Translation: i m looking forward to it . <end>\n",
            "\n",
            "Epoch #260, Loss 0.0109, Time 2.09 sec\n",
            "Input: <start> ¿ Tenes experiencia profesional ? <end>\n",
            "Target: <start> Do you have professional experience ? <end>\n",
            "Translation: do you have professional experience ? <end>\n",
            "\n",
            "Epoch #270, Loss 0.0227, Time 2.09 sec\n",
            "Input: <start> Tom no puede correr tan rapido como Mary . <end>\n",
            "Target: <start> Tom can t run as fast as Mary . <end>\n",
            "Translation: tom can t run as fast as mary . <end>\n",
            "\n",
            "Epoch #280, Loss 0.0391, Time 2.36 sec\n",
            "Input: <start> Tom tiene un dolor de garganta . <end>\n",
            "Target: <start> Tom has a sore throat . <end>\n",
            "Translation: tom has a sore throat . <end>\n",
            "\n",
            "Epoch #290, Loss 0.0110, Time 2.09 sec\n",
            "Input: <start> ¿ Cuando acaba la actuacion ? <end>\n",
            "Target: <start> When does the performance end ? <end>\n",
            "Translation: when does the performance end ? <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0t6zo8PwwL3B",
        "colab_type": "code",
        "outputId": "f587c4a3-4b25-4fd4-fcb6-ec2d47f9ba4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "references_spanish, hypotheses_spanish, inputs_spanish = [], [],[]\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references_spanish.append(target_sent)\n",
        "  hypotheses_spanish.append(\"<start> \" + translation)\n",
        "  inputs_spanish.append(input_sent)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses_spanish, [references_spanish])\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=65.46592398170365, counts=[16298, 11744, 9363, 7364], totals=[19525, 17525, 15525, 13525], precisions=[83.47247119078105, 67.01283880171184, 60.309178743961354, 54.44731977818854], bp=1.0, sys_len=19525, ref_len=19483)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R2la6wvQWVO3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PART 3 - Back Translation\n",
        "\n",
        "For back translation the following workflow is used:\n",
        "\n",
        "Translate English to Spanish ----> Store translated Spanish sentence in *hypotheses* array ----> Translate *hypotheses* array to English ----> Compare  with original English sentence\n",
        "\n",
        "\n",
        "We first create a new array of tuples which will be our new *sentences* array. The input sentence is given as the hypotheses, and target as the original English sentence. We then ttokenise the new input sentences on the **same** tokenizer used in the Spanish to English model above. \n",
        "\n",
        "The rest of the procedure that's followed is the same as above. The BLEU score is calculated based on the original English sentence and the new translated English sentence. \n",
        "\n",
        "The BLEU score acheived is 63.4 (lower than the previous two BLEU scores)"
      ]
    },
    {
      "metadata": {
        "id": "d1LtpERjCKPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tr = []\n",
        "\n",
        "for i in range(0,len(hypotheses_eng)):\n",
        "  data_point = []\n",
        "  data_point.append(hypotheses_eng[i])\n",
        "  data_point.append(input_eng[i])\n",
        "  tr.append(tuple(data_point))\n",
        "  \n",
        "sentences = tr\n",
        "\n",
        "source_sentences = hypotheses_eng\n",
        "source_data = source_tokenizer.texts_to_sequences(source_sentences)\n",
        "source_data = tf.keras.preprocessing.sequence.pad_sequences(source_data, padding='post')\n",
        "\n",
        "source_vocab_size = len(source_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxdKJpY__zGM",
        "colab_type": "code",
        "outputId": "d6f8d875-c686-435a-e6e5-73af9aa0fed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "references_back, hypotheses_back, inputs_back = [], [],[]\n",
        "\n",
        "for i in range(len(hypotheses_eng)):\n",
        "  input_sent, target_sent, translation = translate()\n",
        "  references_back.append(target_sent)\n",
        "  hypotheses_back.append(\"<start> \" + translation)\n",
        "  inputs_back.append(input_sent)\n",
        "  \n",
        "results = sacrebleu.raw_corpus_bleu(hypotheses_back, [references_back])\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=63.44463190858362, counts=[15889, 11362, 8986, 7060], totals=[19435, 17435, 15435, 13435], precisions=[81.75456650373039, 65.16776598795526, 58.21833495302883, 52.54931149981392], bp=0.9985089593756523, sys_len=19435, ref_len=19464)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vEpy1CW15zgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "304ea96b-a972-4115-a8ed-acd3522fe460"
      },
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "  print(\"Input2:\\t\", references_back[i])\n",
        "  print(\"Input2: \\t\", inputs_back[i])\n",
        "  print(\"Output: \\t\", hypotheses_back[i])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input2:\t <start> What is the book about ? <end>\n",
            "Input2: \t <start> ¿ de que trata el libro ? <end>\n",
            "Output: \t <start> what is the book about ? <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> Let s put this near the door . <end>\n",
            "Input2: \t <start> pongamos esto cerca de la puerta . <end>\n",
            "Output: \t <start> let s put this near the door . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> Hundreds of soldiers ate in silence around their campfires . <end>\n",
            "Input2: \t <start> cientos de soldados comieron en silencio alrededor de sus fogatas . <end>\n",
            "Output: \t <start> hundreds of soldiers ate in silence around their campfires . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> I am repairing the washing machine . <end>\n",
            "Input2: \t <start> estoy arreglando el lavarropa . <end>\n",
            "Output: \t <start> i am repairing the washing machine . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> Tom didn t come to the last meeting . <end>\n",
            "Input2: \t <start> tom no vino a la ultima reunion . <end>\n",
            "Output: \t <start> tom didn t come to the last meeting . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> Sleeping in class is not allowed . <end>\n",
            "Input2: \t <start> no se permite dormirse en clase . <end>\n",
            "Output: \t <start> sleeping in class is not allowed . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> The people I lend money to never pay me back . <end>\n",
            "Input2: \t <start> las personas a las que les presto dinero nunca me lo devuelven . <end>\n",
            "Output: \t <start> the people i lend money to never pay me back . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> I found this watch at the station . <end>\n",
            "Input2: \t <start> encontre este reloj en la estacion . <end>\n",
            "Output: \t <start> i found this watch at his room . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> Alexander Hamilton was a proud man . <end>\n",
            "Input2: \t <start> alexander hamilton era un hombre orgulloso . <end>\n",
            "Output: \t <start> alexander hamilton was a proud man . <end>\n",
            "\n",
            "\n",
            "Input2:\t <start> It s incredible ! <end>\n",
            "Input2: \t <start> increible ! <end>\n",
            "Output: \t <start> it s incredible ! <end>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}